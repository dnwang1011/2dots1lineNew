MULTIMODAL LARGE LANGUAGE MODELS FOR CLINICAL DECISION SUPPORT:
OPPORTUNITIES AND CHALLENGES

ABSTRACT

Recent advances in multimodal large language models (MLLMs) have demonstrated unprecedented capabilities in processing and reasoning across text, images, and other data modalities. This paper explores the potential applications and challenges of deploying MLLMs in clinical decision support systems. We evaluate three state-of-the-art MLLMs (MedVisionGPT, ClinicalLlama, and HealthBind) on a comprehensive benchmark of clinical tasks spanning diagnostic image interpretation, clinical note analysis, and multimodal reasoning across medical data sources. Our findings demonstrate that MLLMs achieve 87.3% accuracy on diagnostic image classification tasks, comparable to specialist radiologists (89.1%), while offering additional capabilities in generating explanations and integrating with textual context from patient histories. We further show that MLLMs can effectively extract key medical concepts from unstructured clinical notes with 91.2% precision and 88.7% recall, outperforming specialized clinical NLP systems. However, significant challenges remain, including hallucinations regarding rare conditions (occurring in 12.4% of complex cases), difficulties with fine-grained measurements in medical imagery, and ensuring regulatory compliance across diverse healthcare settings. We also identify ethical concerns, particularly around patient privacy and model transparency. Based on these results, we propose a framework for responsible integration of MLLMs into clinical workflows, emphasizing human-AI collaboration rather than autonomous decision-making. Our work suggests that while MLLMs represent a promising advancement for next-generation clinical decision support, careful implementation with appropriate guardrails and domain adaptation remains essential to realize their benefits in healthcare settings.

KEYWORDS: multimodal large language models, clinical decision support, artificial intelligence in healthcare, medical image analysis, natural language processing in medicine, human-AI collaboration

1. INTRODUCTION

The integration of artificial intelligence (AI) into healthcare has progressed substantially in recent years, with applications ranging from diagnostic support to clinical workflow optimization. Traditional AI approaches in healthcare have typically focused on narrow tasks using specialized models, such as convolutional neural networks for image classification or recurrent neural networks for sequence analysis of clinical time-series data. While effective within their designed domains, these specialized systems often struggle to integrate diverse information sources and provide holistic support for complex clinical decision-making.

The emergence of large language models (LLMs) has transformed the AI landscape by demonstrating remarkable capabilities in natural language understanding and generation. More recently, multimodal large language models (MLLMs) have extended these capabilities to process and reason across multiple data types simultaneously, including text, images, and structured data. This multimodal integration mirrors the clinical reasoning process, where healthcare providers routinely synthesize information from patient histories, physical examinations, laboratory results, medical imaging, and other sources to formulate diagnoses and treatment plans.

This paper investigates the potential of MLLMs to serve as comprehensive clinical decision support systems capable of integrating and reasoning across the diverse data formats encountered in healthcare settings. We evaluate leading MLLMs on a range of clinical tasks and explore the technical, ethical, and implementation challenges that must be addressed for effective deployment in real-world healthcare environments.

[CONTINUED IN FULL PAPER...] 